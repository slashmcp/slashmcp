import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import {
  Agent,
  type AgentInputItem,
  type Handoff,
  type Tool,
  Runner,
} from "https://esm.sh/@openai/agents@0.0.9";

type Provider = "openai" | "anthropic" | "gemini";

const allowedOrigins = Deno.env.get("ALLOWED_ORIGINS")?.split(",").map(origin => origin.trim()) ?? ["*"];
const SYSTEM_PROMPT =
  "You are a helpful AI research assistant speaking aloud through text-to-speech. Respond in natural spoken sentences, avoid stage directions, asterisks, or emojis, and keep punctuation simple so it sounds good when read aloud. Provide clear answers, cite important facts conversationally, and offer actionable insight when useful.";

const encoder = new TextEncoder();

const PROJECT_URL = Deno.env.get("PROJECT_URL") ?? Deno.env.get("SUPABASE_URL") ?? "";
const MCP_GATEWAY_URL = PROJECT_URL ? `${PROJECT_URL.replace(/\/+$/, "")}/functions/v1/mcp` : "";

function getCorsHeaders(origin: string | null): Record<string, string> {
  const isAllowed = !origin || allowedOrigins.includes("*") || allowedOrigins.includes(origin);
  return {
    "Access-Control-Allow-Origin": isAllowed && origin ? origin : "*",
    "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
    "Access-Control-Allow-Methods": "POST, OPTIONS",
    "Access-Control-Max-Age": "86400",
    Vary: "Origin",
  };
}

function respondWithStreamedText(text: string, corsHeaders: Record<string, string>) {
  const stream = new ReadableStream<Uint8Array>({
    start(controller) {
      if (text) {
        const payload = JSON.stringify({ choices: [{ delta: { content: text } }] });
        controller.enqueue(encoder.encode(`data: ${payload}\n\n`));
      }
      controller.enqueue(encoder.encode("data: [DONE]\n\n"));
      controller.close();
    },
  });

  return new Response(stream, {
    headers: { ...corsHeaders, "Content-Type": "text/event-stream" },
  });
}

function mapMessagesForAnthropic(messages: Array<{ role: string; content: string }>) {
  return messages.map(message => ({
    role: message.role === "assistant" ? "assistant" : "user",
    content: [{ type: "text", text: message.content }],
  }));
}

function mapMessagesForGemini(messages: Array<{ role: string; content: string }>) {
  return messages.map(message => ({
    role: message.role === "assistant" ? "model" : "user",
    parts: [{ text: message.content }],
  }));
}

// --- Multi-agent setup using OpenAI Agents SDK for the OpenAI provider ---

const mcpProxyTool: Tool = {
  name: "mcp_proxy",
  description:
    "Executes a registered MCP command via the slashmcp backend. Input must be a string in the format: /<server-id> <command> [param=value...]",
  parameters: {
    type: "object",
    properties: {
      command: {
        type: "string",
        description: 'The full MCP command string, e.g., "/alphavantage-mcp get_stock_chart symbol=NVDA"',
      },
    },
    required: ["command"],
  },
  async run({ command }: { command: string }) {
    if (!MCP_GATEWAY_URL) {
      return "MCP gateway URL is not configured on the server.";
    }

    const trimmed = (command ?? "").trim();
    if (!trimmed.startsWith("/")) {
      return 'Invalid MCP command format. Expected something like "/alphavantage-mcp get_quote symbol=NVDA".';
    }

    const [serverAndSuffix, ...paramTokens] = trimmed.split(/\s+/);
    const serverId = serverAndSuffix.slice(1); // strip leading "/"

    // Assume the first token after the server id is the MCP command name.
    let mcpCommand: string | undefined;
    const args: Record<string, string> = {};

    if (paramTokens.length > 0) {
      mcpCommand = paramTokens.shift()!;
    }

    for (const token of paramTokens) {
      const eqIndex = token.indexOf("=");
      if (eqIndex <= 0) continue;
      const key = token.slice(0, eqIndex);
      const value = token.slice(eqIndex + 1);
      args[key] = value;
    }

    try {
      const response = await fetch(MCP_GATEWAY_URL, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          serverId,
          command: mcpCommand,
          args,
          positionalArgs: [],
        }),
      });

      if (!response.ok) {
        const errorText = await response.text().catch(() => "");
        throw new Error(
          `MCP gateway request failed with status ${response.status}${
            errorText ? `: ${errorText.slice(0, 200)}` : ""
          }`,
        );
      }

      const data = await response.json();
      return JSON.stringify(data, null, 2);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      return `Error executing MCP command: ${message}`;
    }
  },
};

const mcpToolAgent = new Agent({
  name: "MCP_Tool_Agent",
  instructions:
    "You are an expert in executing Model Context Protocol (MCP) commands. Your only tool is the `mcp_proxy`. " +
    "When a user request requires external data or a specific tool, you must formulate the correct MCP command and use the `mcp_proxy` tool. " +
    "You can call any registered MCP server, including:\n" +
    "- `alphavantage-mcp` for stock and market data\n" +
    "- `polymarket-mcp` for prediction market odds\n" +
    "- `gemini-mcp` for lightweight text generation\n" +
    "- `playwright-mcp` or `playwright-wrapper` for browser automation, web scraping, and recursive testing\n" +
    "- `search-mcp` for web search results\n" +
    "For browser automation, web scraping, or research tasks:\n" +
    "- Use `playwright-wrapper` (or `srv_...` ID) with commands like `browser_navigate`, `browser_snapshot`, `browser_extract_text`\n" +
    "- For recursive testing of the app itself, navigate to the app URL, get snapshots, and interact with elements\n" +
    "- For research, extract text content from pages and analyze it\n" +
    "When researching websites or testing apps, use browser automation to:\n" +
    "1. Navigate to the URL with `browser_navigate url=...`\n" +
    "2. Get page structure with `browser_snapshot url=...`\n" +
    "3. Extract text with `browser_extract_text url=...` (if available)\n" +
    "4. Take screenshots with `browser_take_screenshot url=...` if visual analysis is needed\n" +
    "Do not answer questions directly; instead, call the tool and return its results.",
  tools: [mcpProxyTool],
});

const finalAnswerAgent = new Agent({
  name: "Final_Answer_Agent",
  instructions:
    "You are the final response generator. Your task is to take the results from the MCP_Tool_Agent and the user's original query, " +
    "and synthesize a concise, helpful, and professional final answer. Do not use any tools.",
});

const mcpHandoff: Handoff = {
  name: "handoff_to_mcp_tool",
  description:
    "Use this handoff when the user's request requires external data or tool execution (e.g., stock prices, market odds, document analysis).",
  targetAgent: mcpToolAgent,
  inputFilter: (input: AgentInputItem[]) => input,
};

const finalHandoff: Handoff = {
  name: "handoff_to_final_answer",
  description: "Use this handoff after the MCP_Tool_Agent has executed its command and returned a result.",
  targetAgent: finalAnswerAgent,
  inputFilter: (input: AgentInputItem[]) => input,
};

const orchestratorAgent = new Agent({
  name: "Orchestrator_Agent",
  instructions:
    "Your primary goal is to determine the best course of action to answer the user's question. " +
    "If the request is a simple chat, answer directly. " +
    "If it requires external data or a tool (like stock prices, prediction markets, document analysis, or browser automation with Playwright), " +
    "use the `handoff_to_mcp_tool` handoff so the MCP_Tool_Agent can call MCP servers via the `mcp_proxy` tool. " +
    "For example, when the user asks you to visit a website, scrape information from a page, or generate/repair Playwright tests, " +
    "you should trigger `handoff_to_mcp_tool` so it can use the `playwright-mcp` server. " +
    "If you receive tool results and further synthesis is needed, use the `handoff_to_final_answer` handoff.",
  handoffs: [mcpHandoff, finalHandoff],
});

serve(async (req) => {
  const origin = req.headers.get("Origin");
  const corsHeaders = getCorsHeaders(origin);

  if (req.method === "OPTIONS") {
    return new Response("ok", {
      status: 200,
      headers: corsHeaders,
    });
  }

  try {
    const { messages, provider } = await req.json();
    if (!Array.isArray(messages)) {
      return new Response(JSON.stringify({ error: "messages must be an array" }), {
        status: 400,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    const normalizedProvider = (provider ?? "openai") as string;
    const selectedProvider: Provider =
      normalizedProvider === "anthropic" || normalizedProvider === "gemini" ? normalizedProvider : "openai";

    const conversation = messages.map((message) => ({
      role: message.role === "assistant" ? "assistant" : "user",
      content: typeof message.content === "string" ? message.content : String(message.content),
    }));

    if (selectedProvider === "openai") {
      const apiKey = Deno.env.get("OPENAI_API_KEY");
      if (!apiKey) {
        throw new Error("OPENAI_API_KEY is not configured");
      }

      // Create runner with API key for this request
      const runner = new Runner({
        model: "gpt-4o-mini",
        apiKey: apiKey,
      });

      const lastUserMessage = conversation.length
        ? conversation[conversation.length - 1]?.content ?? ""
        : "";

      // Run the multi-agent workflow via the OpenAI Agents SDK.
      let finalOutput = "";
      let errorOccurred = false;
      let errorMessage = "";
      const contentParts: string[] = [];

      try {
        const events = await runner.run(
          orchestratorAgent,
          lastUserMessage,
          {
            tools: [mcpProxyTool],
            maxTurns: 15,
            stream: true,
          },
        );

        // Collect all content from the streaming events.
        for await (const event of events as AsyncIterable<{ 
          type: string; 
          output?: unknown; 
          error?: unknown;
          content?: string | unknown;
          text?: string;
        }>) {
          console.log("Event received:", event.type, JSON.stringify(event).slice(0, 200));
          
          if (event.type === "error") {
            errorOccurred = true;
            errorMessage = event.error instanceof Error ? event.error.message : String(event.error);
            console.error("Agent runner error:", event.error);
          } else if (event.type === "finalOutput") {
            if (event.output !== undefined) {
              if (typeof event.output === "string") {
                finalOutput = event.output;
                contentParts.push(event.output);
              } else {
                try {
                  const outputStr = JSON.stringify(event.output);
                  finalOutput = outputStr;
                  contentParts.push(outputStr);
                } catch {
                  finalOutput = String(event.output);
                  contentParts.push(finalOutput);
                }
              }
            }
          } else if (event.type === "content" || event.type === "text") {
            // Collect streaming content
            const content = event.content || event.text;
            if (content) {
              const contentStr = typeof content === "string" ? content : String(content);
              contentParts.push(contentStr);
            }
          } else if (event.type === "newMessage") {
            // Some SDK versions use newMessage events
            const message = event as any;
            if (message.content && typeof message.content === "string") {
              contentParts.push(message.content);
            }
          }
        }
        
        // If we collected content parts but no finalOutput, combine them
        if (!finalOutput && contentParts.length > 0) {
          finalOutput = contentParts.join("");
        }
      } catch (runnerError) {
        errorOccurred = true;
        errorMessage = runnerError instanceof Error ? runnerError.message : String(runnerError);
        console.error("Runner execution error:", runnerError);
        console.error("Error stack:", runnerError instanceof Error ? runnerError.stack : "No stack");
      }

      if (errorOccurred) {
        console.error("Agent execution failed:", errorMessage);
        return new Response(
          JSON.stringify({ 
            error: `Agent execution failed: ${errorMessage}`,
            details: "Check server logs for more information"
          }), 
          {
            status: 500,
            headers: { ...corsHeaders, "Content-Type": "application/json" },
          }
        );
      }

      if (!finalOutput || finalOutput.trim().length === 0) {
        console.warn("No output generated from agent runner. Collected parts:", contentParts.length);
        finalOutput =
          "I was not able to generate a response. Please try rephrasing your question or asking again in a moment.";
      }

      return respondWithStreamedText(finalOutput, corsHeaders);
    }

    if (selectedProvider === "anthropic") {
      const apiKey = Deno.env.get("ANTHROPIC_API_KEY");
      if (!apiKey) {
        throw new Error("ANTHROPIC_API_KEY is not configured");
      }

      const response = await fetch("https://api.anthropic.com/v1/messages", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "x-api-key": apiKey,
          "anthropic-version": "2023-06-01",
        },
        body: JSON.stringify({
          model: "claude-3-haiku-20240307",
          system: SYSTEM_PROMPT,
          max_tokens: 1024,
          messages: mapMessagesForAnthropic(conversation),
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error("Anthropic error:", response.status, errorText);
        return new Response(JSON.stringify({ error: "Anthropic request failed" }), {
          status: response.status,
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        });
      }

      const data = await response.json();
      const text = Array.isArray(data?.content)
        ? data.content
            .map((part: { text?: string }) => part?.text ?? "")
            .join("\n")
            .trim()
        : "";

      return respondWithStreamedText(text, corsHeaders);
    }

    const apiKey = Deno.env.get("GEMINI_API_KEY");
    if (!apiKey) {
      throw new Error("GEMINI_API_KEY is not configured");
    }

    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${apiKey}`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          system_instruction: {
            parts: [{ text: SYSTEM_PROMPT }],
          },
          contents: mapMessagesForGemini(conversation),
        }),
      },
    );

    if (!response.ok) {
      const errorText = await response.text();
      console.error("Gemini error:", response.status, errorText);
      return new Response(JSON.stringify({ error: "Gemini request failed" }), {
        status: response.status,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    const data = await response.json();
    const text = data?.candidates?.[0]?.content?.parts
      ?.map((part: { text?: string }) => part?.text ?? "")
      .join("\n")
      .trim() ?? "";

    return respondWithStreamedText(text, corsHeaders);
  } catch (error) {
    console.error("chat error:", error);
    return new Response(JSON.stringify({ error: error instanceof Error ? error.message : "Unknown error" }), {
      status: 500,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }
});
